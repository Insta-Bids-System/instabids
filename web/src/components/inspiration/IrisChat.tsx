import React, { useState, useRef, useEffect } from 'react'
import { Send, Sparkles, Image as ImageIcon, X } from 'lucide-react'
import { BoardImage } from '@/types'

interface IrisChatProps {
  boardId: string
  boardTitle: string
  images: BoardImage[]
  onGenerateVision: (selectedElements: string[]) => void
  clickedImage?: BoardImage | null
  onImageProcessed?: () => void
}

interface ChatMessage {
  id: string
  type: 'user' | 'assistant' | 'system'
  message: string
  timestamp: Date
  imageContext?: BoardImage
}

export default function IrisChat({ boardId, boardTitle, images, onGenerateVision, clickedImage, onImageProcessed }: IrisChatProps) {
  const [messages, setMessages] = useState<ChatMessage[]>([
    {
      id: '1',
      type: 'assistant',
      message: `Hi! I'm Iris, your design assistant. I can see your ${boardTitle} board. Click on any image to tell me about it, or describe what elements you'd like to combine for your dream space.`,
      timestamp: new Date()
    }
  ])
  const [input, setInput] = useState('')
  const [selectedImages, setSelectedImages] = useState<BoardImage[]>([])
  const [isGenerating, setIsGenerating] = useState(false)
  const messagesEndRef = useRef<HTMLDivElement>(null)

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' })
  }

  useEffect(() => {
    scrollToBottom()
  }, [messages])

  // Handle clicked images from parent
  useEffect(() => {
    if (clickedImage) {
      handleImageClick(clickedImage)
      onImageProcessed?.()
    }
  }, [clickedImage])

  const handleImageClick = (image: BoardImage) => {
    // Add image to selected images
    if (!selectedImages.find(img => img.id === image.id)) {
      setSelectedImages([...selectedImages, image])
      
      // Add system message about the image
      const imageType = image.tags.includes('current') ? 'current space' : 
                      image.tags.includes('vision') ? 'vision' : 'inspiration'
      const features = image.ai_analysis?.key_features || []
      
      const message: ChatMessage = {
        id: Date.now().toString(),
        type: 'system',
        message: `✅ Added ${imageType} image to conversation: ${image.ai_analysis?.description || 'No description'}${features.length > 0 ? `. Features: ${features.join(', ')}` : ''}`,
        timestamp: new Date(),
        imageContext: image
      }
      
      setMessages(prev => [...prev, message])
      
      // Also send this to the real Iris API so it has context
      fetch('http://localhost:8008/api/iris/chat', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          message: `User clicked on ${imageType} image: ${image.ai_analysis?.description}. Features: ${features.join(', ')}`,
          homeowner_id: '550e8400-e29b-41d4-a716-446655440001',
          board_id: boardId,
          conversation_context: messages.map(m => ({
            role: m.type === 'user' ? 'user' : 'assistant',
            content: m.message
          }))
        })
      }).catch(err => console.error('Error sending image context to Iris:', err))
    }
  }

  const handleSend = async () => {
    if (!input.trim()) return

    const userMessage: ChatMessage = {
      id: Date.now().toString(),
      type: 'user',
      message: input,
      timestamp: new Date()
    }

    setMessages(prev => [...prev, userMessage])
    setInput('')

    // Make real API call to Iris backend
    try {
      const response = await fetch('http://localhost:8008/api/iris/chat', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          message: input,
          homeowner_id: '550e8400-e29b-41d4-a716-446655440001', // Demo user
          board_id: boardId,
          conversation_context: messages.map(m => ({
            role: m.type === 'user' ? 'user' : 'assistant',
            content: m.message
          }))
        })
      })

      if (response.ok) {
        const data = await response.json()
        
        const assistantMessage: ChatMessage = {
          id: Date.now().toString(),
          type: 'assistant',
          message: data.response,
          timestamp: new Date()
        }
        setMessages(prev => [...prev, assistantMessage])

        // Check if image was generated by backend
        if (data.image_generated && data.image_url) {
          // Backend already generated the image
          setIsGenerating(false)
          // You can add logic here to display the generated image
          console.log('Image generated by backend:', data.image_url)
        } else if (input.toLowerCase().includes('generate') || input.toLowerCase().includes('create') || input.toLowerCase().includes('show')) {
          // Fall back to frontend generation if backend didn't generate
          handleGeneration()
        }
      } else {
        // Fallback to simulation if API fails
        simulateIrisResponse(input)
      }
    } catch (error) {
      console.error('Iris API error:', error)
      // Fallback to simulation if API fails  
      simulateIrisResponse(input)
    }
  }

  const simulateIrisResponse = (userInput: string) => {
    // Simulate Iris analyzing the selected images and user input
    setTimeout(() => {
      const currentImages = selectedImages.filter(img => img.tags.includes('current'))
      const inspirationImages = selectedImages.filter(img => !img.tags.includes('current'))

      let response = ''

      if (currentImages.length === 0) {
        response = "I notice you haven't selected your current space photo yet. Click on your current room photo so I know what we're working with."
      } else if (inspirationImages.length === 0) {
        response = "Great! I can see your current space. Now click on some inspiration images to show me what style elements you like."
      } else {
        // Extract elements from inspiration images
        const allFeatures = inspirationImages.flatMap(img => 
          img.ai_analysis?.key_features || []
        )
        const uniqueFeatures = [...new Set(allFeatures)]

        response = `Perfect! Looking at your inspiration images, I see these elements:\n\n${uniqueFeatures.map(f => `• ${f}`).join('\n')}\n\nWhich of these specific elements would you like to add to your current space? Remember, we'll keep your exact layout and just add the elements you choose.`
      }

      const assistantMessage: ChatMessage = {
        id: Date.now().toString(),
        type: 'assistant',
        message: response,
        timestamp: new Date()
      }

      setMessages(prev => [...prev, assistantMessage])
    }, 1000)
  }

  const handleGeneration = () => {
    const currentImage = selectedImages.find(img => img.tags.includes('current'))
    const inspirationImages = selectedImages.filter(img => !img.tags.includes('current'))

    if (!currentImage || inspirationImages.length === 0) {
      const errorMessage: ChatMessage = {
        id: Date.now().toString(),
        type: 'assistant',
        message: "I need both your current space photo and at least one inspiration image to generate a vision. Please select them by clicking on the images.",
        timestamp: new Date()
      }
      setMessages(prev => [...prev, errorMessage])
      return
    }

    setIsGenerating(true)

    // Extract elements mentioned in the conversation
    const lastUserMessages = messages
      .filter(m => m.type === 'user')
      .slice(-3)
      .map(m => m.message)
      .join(' ')

    onGenerateVision([lastUserMessages])

    const generatingMessage: ChatMessage = {
      id: Date.now().toString(),
      type: 'assistant',
      message: "I'm generating your vision now! This will show your exact current space enhanced with the specific elements you requested...",
      timestamp: new Date()
    }
    setMessages(prev => [...prev, generatingMessage])
  }

  return (
    <div className="bg-white rounded-lg shadow-sm border border-gray-200 h-[500px] flex flex-col">
      {/* Header */}
      <div className="px-4 py-3 border-b border-gray-200 flex items-center gap-2">
        <Sparkles className="w-5 h-5 text-primary-600" />
        <h3 className="font-medium text-gray-900">Chat with Iris</h3>
        <span className="text-sm text-gray-500 ml-auto">Design Assistant</span>
      </div>

      {/* Selected Images Bar */}
      {selectedImages.length > 0 && (
        <div className="px-4 py-2 bg-gray-50 border-b border-gray-200">
          <div className="flex items-center gap-2 overflow-x-auto">
            <span className="text-sm text-gray-600">Selected:</span>
            {selectedImages.map(img => (
              <div key={img.id} className="relative">
                <img 
                  src={img.thumbnail_url || img.image_url} 
                  alt=""
                  className="w-12 h-12 rounded object-cover"
                />
                <button
                  onClick={() => setSelectedImages(prev => prev.filter(i => i.id !== img.id))}
                  className="absolute -top-1 -right-1 bg-red-500 text-white rounded-full p-0.5"
                >
                  <X className="w-3 h-3" />
                </button>
              </div>
            ))}
          </div>
        </div>
      )}

      {/* Messages */}
      <div className="flex-1 overflow-y-auto px-4 py-4 space-y-4">
        {messages.map(message => (
          <div
            key={message.id}
            className={`flex ${message.type === 'user' ? 'justify-end' : 'justify-start'}`}
          >
            <div
              className={`max-w-[80%] rounded-lg px-4 py-2 ${
                message.type === 'user'
                  ? 'bg-primary-600 text-white'
                  : message.type === 'system'
                  ? 'bg-gray-100 text-gray-600 text-sm italic'
                  : 'bg-gray-100 text-gray-900'
              }`}
            >
              {message.message.split('\n').map((line, i) => (
                <div key={i}>{line}</div>
              ))}
              {message.imageContext && (
                <img 
                  src={message.imageContext.thumbnail_url} 
                  alt=""
                  className="mt-2 w-20 h-20 rounded object-cover"
                />
              )}
            </div>
          </div>
        ))}
        <div ref={messagesEndRef} />
      </div>

      {/* Input */}
      <div className="px-4 py-3 border-t border-gray-200">
        <div className="flex gap-2">
          <input
            type="text"
            value={input}
            onChange={(e) => setInput(e.target.value)}
            onKeyPress={(e) => e.key === 'Enter' && handleSend()}
            placeholder="Tell Iris what elements you want..."
            className="flex-1 px-3 py-2 border border-gray-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-primary-500"
          />
          <button
            onClick={handleSend}
            disabled={!input.trim() || isGenerating}
            className="px-4 py-2 bg-primary-600 text-white rounded-lg hover:bg-primary-700 disabled:opacity-50 disabled:cursor-not-allowed"
          >
            <Send className="w-5 h-5" />
          </button>
        </div>
        <p className="text-xs text-gray-500 mt-2">
          <ImageIcon className="w-3 h-3 inline mr-1" />
          Click images above to add them to the conversation
        </p>
      </div>
    </div>
  )
}